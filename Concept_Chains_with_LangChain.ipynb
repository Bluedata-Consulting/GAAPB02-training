{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38864d97",
   "metadata": {},
   "source": [
    "## Working with Langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22f712c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install langchain langchain-experimental langchain-core langchain-community langchain-openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb5b79e",
   "metadata": {},
   "source": [
    "#### Langchain components: ChatModels, Prompt Templates, Parsers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de5fa565",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the heart of Karnataka, a city does bloom,  \n",
      "Bangalore, oh Bangalore, where dreams find room.  \n",
      "A tapestry woven with culture and grace,  \n",
      "In your bustling embrace, we find our place.  \n",
      "\n",
      "Tech towers rising like stars in the night,  \n",
      "Innovators gather, igniting the light.  \n",
      "Silicon Valley whispers, ideas take flight,  \n",
      "In the pulse of your streets, futures shine bright.  \n",
      "\n",
      "Lalbagh’s roses, in vibrant array,  \n",
      "Blooming with stories, they dance in the sway.  \n",
      "From gardens to tech parks, a blend so divine,  \n",
      "Where the old meets the new, in harmonious line.  \n",
      "\n",
      "The aroma of filter coffee fills the air,  \n",
      "In cozy adda, souls gather and share.  \n",
      "The flavors of history on each bustling street,  \n",
      "From dosa to idli, a culinary treat.  \n",
      "\n",
      "Vibrant markets pulse with life and color,  \n",
      "Malleswaram’s heart, where moments don’t flutter.  \n",
      "Heritage mingles with the contemporary beat,  \n",
      "At every corner, a new tale we meet.  \n",
      "\n",
      "When summer’s sun scorches, and rains come to play,  \n",
      "The city transforms, in a magical way.  \n",
      "From Cubbon Park’s shade to Nandi’s strong gaze,  \n",
      "Bangalore, you dazzle, in life’s endless maze.  \n",
      "\n",
      "The laughter of children, the wisdom of age,  \n",
      "In every heartbeat, you write a new page.  \n",
      "A city of dreams, both humble and grand,  \n",
      "Bangalore, beloved, forever you stand.  \n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import AzureChatOpenAI\n",
    "\n",
    "model = AzureChatOpenAI(api_version=\"2024-12-01-preview\",model='telcogpt')\n",
    "\n",
    "op = model.invoke(\"write a poem on the city Bangalore\")\n",
    "print(op.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c46e5be5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['language', 'text'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['language'], input_types={}, partial_variables={}, template='Translate the following into {language}'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['text'], input_types={}, partial_variables={}, template='{text}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chatprompt template\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "systemprompt = \"Translate the following into {language}\"\n",
    "prompttempate = ChatPromptTemplate([(\"system\",systemprompt),(\"user\",\"{text}\")])\n",
    "prompttempate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd892d50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[SystemMessage(content='Translate the following into hindi', additional_kwargs={}, response_metadata={}), HumanMessage(content='How are you?', additional_kwargs={}, response_metadata={})])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompttempate.invoke({\"language\":\"hindi\",\"text\":\"How are you?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "373d0234",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='आप कैसे हैं?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 5, 'prompt_tokens': 20, 'total_tokens': 25, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini', 'system_fingerprint': 'fp_7a53abb7a2', 'id': 'chatcmpl-BX0NDvWWG6DvfwfLznU3EX3KF6AlR', 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'finish_reason': 'stop', 'logprobs': None, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}, id='run-93bef2d6-f54f-4192-a1bc-8a1d1841fa31-0', usage_metadata={'input_tokens': 20, 'output_tokens': 5, 'total_tokens': 25, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# parsers\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "parser = StrOutputParser()\n",
    "\n",
    "response = model.invoke(prompttempate.invoke({\"language\":\"hindi\",\"text\":\"HOW ARE YOU?\"}))\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "873b89db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'आप कैसे हैं?'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser.invoke(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f48813fb",
   "metadata": {},
   "source": [
    "## Chains\n",
    "- a static sequence of steps involving multiple compnents such as LLMs, parsers, tools, prompts, loaders etc.\n",
    "- can be used to automate a rule based, linear or non linear (Conditional chains) workflows involving LLMs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e3f2385a",
   "metadata": {},
   "outputs": [],
   "source": [
    "translation_chain = prompttempate | model | parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "80e5038d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'நன்றி'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translation_chain.invoke({\"language\":\"tamil\",\"text\":\"THANK YOU\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08bf8089",
   "metadata": {},
   "source": [
    "### Code Generation and Analysis Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cb8b5300",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```python\n",
      "def fibonacci(n):\n",
      "    fib_series = []\n",
      "    a, b = 0, 1\n",
      "    for _ in range(n):\n",
      "        fib_series.append(a)\n",
      "        a, b = b, a + b\n",
      "    return fib_series\n",
      "\n",
      "n = int(input(\"Enter the number of terms: \"))\n",
      "print(fibonacci(n))\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "generateprompt = ChatPromptTemplate.from_template(\"write a python code for {task}, only provide python code no other additional text\")\n",
    "\n",
    "chain1 = generateprompt | model | parser\n",
    "\n",
    "op = chain1.invoke({\"task\":'fibonacci series'})\n",
    "print(op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "51f52505",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_prompt = ChatPromptTemplate.from_template(\"analyze the provided code and estimate time complexity, do not provide any additional text {code}\")\n",
    "chain2 = analyze_prompt | model | parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f0ca91d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```python\n",
      "def fibonacci(n):\n",
      "    a, b = 0, 1\n",
      "    series = []\n",
      "    for _ in range(n):\n",
      "        series.append(a)\n",
      "        a, b = b, a + b\n",
      "    return series\n",
      "\n",
      "n = int(input(\"Enter the number of Fibonacci numbers to generate: \"))\n",
      "print(fibonacci(n))\n",
      "```\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def patch_format(code):\n",
    "    print(code)\n",
    "    print(\"----\"*10)\n",
    "    return {\"code\":code}\n",
    "\n",
    "finalchain = chain1 | patch_format | chain2\n",
    "\n",
    "op = finalchain.invoke({\"task\":\"fibonacci series\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810b641f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```python\n",
      "def fibonacci(n):\n",
      "    fib_sequence = []\n",
      "    a, b = 0, 1\n",
      "    for _ in range(n):\n",
      "        fib_sequence.append(a)\n",
      "        a, b = b, a + b\n",
      "    return fib_sequence\n",
      "\n",
      "n = int(input(\"Enter the number of terms: \"))\n",
      "print(fibonacci(n))\n",
      "```\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "chain = generateprompt | model | parser | patch_format | analyze_prompt | model | parser\n",
    "op = chain.invoke({\"task\":\"fibonacci series\"})\n",
    "print(op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19128150",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gen-ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
